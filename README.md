In this tutorial, we explore some of the infrastructure and platform requirements for large model training, and to support the training of many models by many teams. We focus specifically on experiment tracking (using [MLFlow](https://mlflow.org/)).

Follow along at [ML Experiment Tracking with MLFlow](https://teaching-on-testbeds.github.io/mlflow-chi/).

Note: this tutorial requires advance reservation of specific hardware! You will need a node with 2 GPUs suitable for model training. You should reserve a 3-hour block.

You can use either:

* a `gpu_mi100` at CHI@TACC, or
* a `compute_liqid` at CHI@TACC


---

This material is based upon work supported by the National Science Foundation under Grant No. 2230079.
